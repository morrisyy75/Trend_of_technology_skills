{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#executing this code so that the client application Collecting Jobs API will be accessing this code executing on the server\n!pip install flask\n!wget  https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DA0321EN-SkillsNetwork/labs/module%201/Accessing%20Data%20Using%20APIs/jobs.json","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import flask\nfrom flask import request, jsonify\nimport requests\nimport re\n\ndef get_data(key,value,current):\n    results = list()\n    pattern_dict = {\n        'C'      : '(C)',\n        'C++'    : '(C\\+\\+)',\n        'Java'   :'(Java)',\n        'C#'     : '(C\\#)',\n        'Python' :'(Python)',\n        'Scala' : '(Scala)',\n        'Oracle' : '(Oracle)',\n        'SQL Server': '(SQL Server)',\n        'MySQL Server' :'(MySQL Server)',\n        'PostgreSQL':'(PostgreSQL)',\n        'MongoDB'    : '(MongoDB)',\n        'JavaScript'    : '(JavaScript)',\n        'Los Angeles' :'(Los Angeles)',\n        'New York':'(New York)',\n        'San Francisco':'(San Francisco)',\n        'Washington DC':'(Washington DC)',\n        'Seattle':'(Seattle)',\n        'Austin':'(Austin)',\n        'Detroit':'(Detroit)',\n        \n        \n        \n        \n        \n    }\n    for rec in current:\n        print(rec[key])\n        print(type(rec[key]))\n        print(rec[key].find(value))\n        #if rec[key].find(value) != -1:\n        import re\n        #reex_str = \"\"\"(C)|(C\\+\\+)|(JavaScript)|(Java)|(C\\#)|(Python)|(Scala)|(Oracle)|(SQL Server)|(MySQL Server)|(PostgreSQL)|(MongoDB)\"\"\"\n        if re.search(pattern_dict[value],rec[key]) != None:\n            results.append(rec)\n    return results\n\napp = flask.Flask(__name__)\n\nimport json\ndata = None\nwith open('jobs.json',encoding='utf-8') as f:\n    # returns JSON object as\n    # a dictionary\n    data = json.load(f)\n    \n    \n\n@app.route('/', methods=['GET'])\ndef home():\n    \n    return '''<h1>Welcome to flask JOB search API</p>'''\n\n\n@app.route('/data/all', methods=['GET'])\ndef api_all():\n    return jsonify(data)\n\n\n@app.route('/data', methods=['GET'])\ndef api_id():\n    # Check if keys such as Job Title,KeySkills, Role Category and others  are provided as part of the URL.\n    #  Assign the keys to the corresponding variables..\n    # If no key is provided, display an error in the browser.\n    res = None\n    for req in request.args:\n        \n        if req == 'Job Title':\n            key = 'Job Title'\n        elif req == 'Job Experience Required' :\n            key='Job Experience Required'\n        elif req == 'Key Skills' :\n            key='Key Skills'\n            \n        elif req == 'Role Category' :\n            key='Role Category'\n        elif req == 'Location' :\n            key='Location'\n        \n        elif req == 'Functional Area' :\n            key='Functional Area'\n        \n        elif req == 'Industry' :\n            key='Industry'\n        elif req == 'Role' :\n            key='Role'\n        elif req==\"id\":\n             key=\"id\"\n        else:\n            pass\n    \n        value = request.args[key]\n        if (res==None):\n            res = get_data(key,value,data)\n        else:\n            res = get_data(key,value,res)\n\n    # Use the jsonify function from Flask to convert our list of\n    # Python dictionaries to the JSON format.\n    return jsonify(res)\n\napp.run()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Import required libraries\nimport pandas as pd\nimport json\nimport requests ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Write a function to get the number of jobs for the Python technology.\napi_url=\"http://127.0.0.1:5000/data\"\ndef get_number_of_jobs_T(technology):\n    number_of_jobs = 0\n    payload = {\"Key Skills\":technology}\n    r = requests.get(api_url, params = payload)\n    if r.ok:\n        data = r.json()\n        number_of_jobs+=len(data)\n        \n   \n    return technology,number_of_jobs","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Calling the function for Python and checking if it works.\nget_number_of_jobs_T(\"Python\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Write a function to find number of jobs in US for a location of our choice.\ndef get_number_of_jobs_L(location):\n    number_of_jobs = 0\n    payload = {\"Location\":location}\n    r = requests.get(api_url, params = payload)\n    if r.ok:\n        data = r.json()\n        number_of_jobs=len(data)\n    return location,number_of_jobs","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Call the function for Los Angeles and check if it is working.\n\nget_number_of_jobs_L(\"Los Angeles\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Store the results in an excel file\nr = requests.get(api_url, params = 'Location')\nprint (r)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"locations = ['Los Angeles',\n'New York',\n'San Francisco',\n'Washington DC',\n'Seattle',\n'Austin',\n'Detroit']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install openpyxl\nimport openpyxl\nfrom openpyxl import Workbook\nwb = Workbook()\nws = wb.active\nws.append(['Job_Title', 'Location'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for location in locations:\n    job_posting_count = get_number_of_jobs_L(location)\n    print(job_posting_count)\n    ws.append(['location','number_of_jobs'])\nwb.save(\"job_postings.xlsx\")   ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"techs = ['C', 'C#', 'C++', 'Java', 'JavaScript', 'Python', 'Scala', 'Oracle', 'SQL Server', 'MySQL Server', 'PostgreSQL', 'MongoDB']\nfor tech in techs:\n    job_counts = get_number_of_jobs_T (tech)\n    ws.append(['technology','number_of_jobs'])\n    print (job_counts)\nwb.save(\"job_postings_tech.xlsx\")\nif ws.max_row > 3:\n    print(\"Data was successfully written to the spreadsheet.\")\nelse:\n    print(\"No data was written to the spreadsheet.\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}
